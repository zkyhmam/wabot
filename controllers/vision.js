const fs = require('fs').promises;
const fsSync = require('fs');
const path = require('path');
const { google } = require('googleapis');
const { sendFormattedMessage, sendErrorMessage } = require('./messageUtils');
const { downloadContentFromMessage } = require('@whiskeysockets/baileys');
const ffmpeg = require('fluent-ffmpeg');

// Constants
const MAX_IMAGE_SIZE = 10 * 1024 * 1024; // 10MB
const MAX_RETRY_ATTEMPTS = 3;
const TEMP_DIR = path.join(__dirname, '..', 'temp');
const API_TIMEOUT = 30000; // 30 seconds
const SERVICE_ACCOUNT_FILE = path.join(__dirname, '..', 'config', 'serviceAccount.json'); // Ù…Ø³Ø§Ø± Ù…Ù„Ù JSON

// Initialize Google Cloud Vision API with Service Account
let vision;
(async () => {
    try {
        const auth = new google.auth.GoogleAuth({
            keyFile: SERVICE_ACCOUNT_FILE,
            scopes: ['https://www.googleapis.com/auth/cloud-platform'],
        });
        const client = await auth.getClient();
        vision = google.vision({
            version: 'v1',
            auth: client,
        });
        console.log('[Image Processor] Google Vision API initialized successfully with service account');
    } catch (error) {
        console.error('[Image Processor] Failed to initialize Google Vision API with service account:', error);
    }
})();

// Cache management
const processedImages = new Set();
const processingQueue = new Map();
let cacheCleanupInterval;

/**
 * Initialize the module and set up required directories and intervals
 */
const initialize = async () => {
    try {
        await fs.mkdir(TEMP_DIR, { recursive: true });
        console.log(`[Image Processor] Temporary directory created at: ${TEMP_DIR}`);

        cacheCleanupInterval = setInterval(() => {
            cleanupCache();
        }, 3600000); // ÙƒÙ„ Ø³Ø§Ø¹Ø©

        return true;
    } catch (error) {
        console.error('[Image Processor] Initialization failed:', error);
        return false;
    }
};

/**
 * Clean up processed image cache and remove old temporary files
 */
const cleanupCache = async () => {
    console.log('[Image Processor] Performing cache cleanup');
    
    if (processedImages.size > 1000) {
        processedImages.clear();
        console.log('[Image Processor] Cleared processed images cache due to size');
    }
    
    try {
        const files = await fs.readdir(TEMP_DIR);
        const currentTime = Date.now();
        
        for (const file of files) {
            const filePath = path.join(TEMP_DIR, file);
            const stats = await fs.stat(filePath);
            if (currentTime - stats.mtimeMs > 7200000) { // 2 Ø³Ø§Ø¹Ø©
                await fs.unlink(filePath);
                console.log(`[Image Processor] Deleted old temporary file: ${filePath}`);
            }
        }
    } catch (error) {
        console.error('[Image Processor] Failed to clean up temporary files:', error);
    }
};

/**
 * Compress image using FFmpeg
 */
const compressImage = (inputPath, outputPath) => {
    return new Promise((resolve, reject) => {
        ffmpeg(inputPath)
            .outputOptions('-vf', 'scale=1024:-1')
            .outputOptions('-q:v', '5')
            .save(outputPath)
            .on('end', resolve)
            .on('error', (err) => reject(new Error(`FFmpeg error: ${err.message}`)));
    });
};

/**
 * Process an image using Google Cloud Vision API
 */
const processImage = async (sock, chatId, imagePath, quotedMessage, retryCount = 0) => {
    const imageKey = `${chatId}:${path.basename(imagePath)}`;
    if (processingQueue.has(imageKey)) return;

    processingQueue.set(imageKey, Date.now());
    processedImages.add(imagePath);

    let statusMsg;
    let compressedImagePath = path.join(TEMP_DIR, `compressed_${path.basename(imagePath)}`);
    
    try {
        statusMsg = await sock.sendMessage(chatId, { text: "*Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©... ğŸ¤–ğŸ”*" }, { quoted: quotedMessage });

        // Ø¶ØºØ· Ø§Ù„ØµÙˆØ±Ø©
        await compressImage(imagePath, compressedImagePath);
        const imageBuffer = await fs.readFile(compressedImagePath);

        const imageBase64 = imageBuffer.toString('base64');
        if (Buffer.byteLength(imageBase64) > MAX_IMAGE_SIZE) {
            throw new Error(`Ø§Ù„ØµÙˆØ±Ø© ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ (${(Buffer.byteLength(imageBase64) / 1024 / 1024).toFixed(2)} Ù…ÙŠØºØ§Ø¨Ø§ÙŠØª)`);
        }

        // Ø¥Ø¹Ø¯Ø§Ø¯ Ø·Ù„Ø¨ Ø§Ù„Ù€ API
        const request = {
            image: { content: imageBase64 },
            features: [
                { type: 'LABEL_DETECTION', maxResults: 5 },
                { type: 'TEXT_DETECTION' },
                { type: 'IMAGE_PROPERTIES' },
                { type: 'SAFE_SEARCH_DETECTION' },
                { type: 'WEB_DETECTION', maxResults: 3 }
            ],
        };

        // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
        const [result] = await Promise.race([
            vision.images.annotate({ requestBody: { requests: [request] } }),
            new Promise((_, reject) => setTimeout(() => reject(new Error('Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨')), API_TIMEOUT))
        ]);

        const response = result.responses[0];
        let analysisText = "*ğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©:*\n\n";

        if (response.labelAnnotations?.length) {
            analysisText += "âœ… *Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©:*\n" + response.labelAnnotations.map(l => `â€¢ ${l.description} (${(l.score * 100).toFixed(2)}%)`).join('\n') + "\n\n";
        }
        if (response.textAnnotations?.length) {
            analysisText += "ğŸ“ *Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯:*\n" + `"${response.textAnnotations[0].description}"\n\n`;
        }
        if (response.imagePropertiesAnnotation?.dominantColors?.colors) {
            analysisText += "ğŸ¨ *Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:*\n" + response.imagePropertiesAnnotation.dominantColors.colors.slice(0, 3)
                .map(c => `â€¢ R:${c.color.red}, G:${c.color.green}, B:${c.color.blue} (${(c.pixelFraction * 100).toFixed(2)}%)`).join('\n') + "\n\n";
        }
        if (response.webDetection?.webEntities?.length) {
            analysisText += "ğŸŒ *Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆÙŠØ¨:*\n" + response.webDetection.webEntities.map(e => `â€¢ ${e.description}`).join('\n') + "\n\n";
        }
        if (response.safeSearchAnnotation) {
            analysisText += "âš ï¸ *ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:*\n" + 
                `â€¢ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ø¨Ø§Ù„ØºÙŠÙ†: ${response.safeSearchAnnotation.adult}\n` +
                `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø³Ø§Ø®Ø±: ${response.safeSearchAnnotation.spoof}\n` +
                `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø·Ø¨ÙŠ: ${response.safeSearchAnnotation.medical}\n` +
                `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†ÙŠÙ: ${response.safeSearchAnnotation.violence}\n` +
                `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø¥Ø¨Ø§Ø­ÙŠ: ${response.safeSearchAnnotation.racy}\n\n`;
        }

        analysisText += "*Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Zaky AI! ğŸ¤–*";
        await sock.sendMessage(chatId, { text: analysisText }, { quoted: quotedMessage, edit: statusMsg.key });

    } catch (error) {
        if (retryCount < MAX_RETRY_ATTEMPTS - 1 && error.message.includes('timeout')) {
            processingQueue.delete(imageKey);
            return processImage(sock, chatId, imagePath, quotedMessage, retryCount + 1);
        }
        const errorMessage = `*âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©:*\n*Ø§Ù„Ø³Ø¨Ø¨:* ${error.message.includes('timeout') ? 'Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨' : error.message}`;
        await sock.sendMessage(chatId, { text: errorMessage }, { quoted: quotedMessage, edit: statusMsg?.key });
        console.error('[Image Processor] Error:', error);
    } finally {
        processingQueue.delete(imageKey);
        await Promise.all([fs.unlink(imagePath).catch(() => {}), fs.unlink(compressedImagePath).catch(() => {})]);
    }
};

/**
 * Handle incoming image messages
 */
const handleImageMessage = async (sock, message) => {
    if (!message?.key || message.key.remoteJid === 'status@broadcast' || message.key.fromMe) return;

    const chatId = message.key.remoteJid;
    const quotedMessage = message;
    const imageMessage = message.message?.imageMessage || message.message?.extendedTextMessage?.contextInfo?.quotedMessage?.imageMessage;

    if (!imageMessage) return;

    const stream = await downloadContentFromMessage(imageMessage, 'image');
    let buffer = Buffer.from([]);
    for await (const chunk of stream) buffer = Buffer.concat([buffer, chunk]);

    const tempImagePath = path.join(TEMP_DIR, `image_${Date.now()}_${Math.random() * 1000}.jpg`);
    await fs.writeFile(tempImagePath, buffer);
    await processImage(sock, chatId, tempImagePath, quotedMessage);
};

/**
 * Shutdown and cleanup resources
 */
const shutdown = async () => {
    clearInterval(cacheCleanupInterval);
    processedImages.clear();
    processingQueue.clear();
    console.log('[Image Processor] Shutdown complete');
};

module.exports = { handleImageMessage, initialize, shutdown, processImage };
