const fs = require('fs');
const path = require('path');
const { google } = require('googleapis');
const { sendFormattedMessage, sendErrorMessage } = require('./messageUtils');
const { downloadContentFromMessage } = require('@whiskeysockets/baileys');

// Initialize Google Cloud Vision API
const vision = google.vision({
    version: 'v1',
    auth: 'AIzaSyDGXCFF6aIa6NVXYwtnQ4aZSjtMNR8KLC0' // REPLACE WITH YOUR API KEY
});

const processedImages = new Set(); // Keep track of processed image paths

const processImage = async (sock, chatId, imagePath, quotedMessage) => {
    if (processedImages.has(imagePath)) {
        console.log(`[Image Processor] Image already processed: ${imagePath}`);
        return;
    }
    processedImages.add(imagePath);

    let statusMsg = await sock.sendMessage(chatId, {
        text: "*Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©... ğŸ¤–ğŸ”*",
    }, { quoted: quotedMessage });

    try {
        const imageBuffer = fs.readFileSync(imagePath);
        const imageBase64 = imageBuffer.toString('base64');

        const request = {
            image: {
                content: imageBase64,
            },
            features: [
                { type: 'LABEL_DETECTION', maxResults: 5 },
                { type: 'TEXT_DETECTION' },
                { type: 'IMAGE_PROPERTIES' },
                { type: 'SAFE_SEARCH_DETECTION' },
                { type: 'WEB_DETECTION', maxResults: 3 }
            ],
        };

        const [result] = await vision.images.annotate({ requestBody: request });
        const labels = result.labelAnnotations;
        const texts = result.textAnnotations;
        const safeSearch = result.safeSearchAnnotation;
        const webEntities = result.webDetection && result.webDetection.webEntities;
        const imageProperties = result.imagePropertiesAnnotation;

        let analysisText = "*ğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©:*\n\n";

        if (labels && labels.length > 0) {
            analysisText += "âœ… *Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©:* \n";
            labels.forEach(label => analysisText += `â€¢ ${label.description} (Ø§Ù„Ø«Ù‚Ø©: ${(label.score * 100).toFixed(2)}%)\n`);
            analysisText += "\n";
        }

        if (texts && texts.length > 0) {
            analysisText += "ğŸ“ *Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©:*\n";
            analysisText += `"${texts[0].description}"\n\n`;
        }

        if (imageProperties && imageProperties.dominantColors && imageProperties.dominantColors.colors) {
            const colors = imageProperties.dominantColors.colors;
            analysisText += "ğŸ¨ *Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:*\n";
            colors.slice(0, 3).forEach(color => {
                const rgb = color.color;
                analysisText += `â€¢ R:${rgb.red}, G:${rgb.green}, B:${rgb.blue} (Ø§Ù„Ù†Ø³Ø¨Ø©: ${(color.pixelFraction * 100).toFixed(2)}%)\n`;
            });
            analysisText += "\n";
        }

        if (webEntities && webEntities.length > 0) {
            analysisText += "ğŸŒ *Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆÙŠØ¨ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©:* \n";
            webEntities.forEach(entity => {
                if (entity.description) {
                    analysisText += `â€¢ ${entity.description}\n`;
                }
            });
            analysisText += "\n";
        }

        if (safeSearch) {
            analysisText += "âš ï¸ *ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:* \n";
            analysisText += `â€¢ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ø¨Ø§Ù„ØºÙŠÙ†: ${safeSearch.adult}\n`;
            analysisText += `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø³Ø§Ø®Ø±: ${safeSearch.spoof}\n`;
            analysisText += `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø·Ø¨ÙŠ: ${safeSearch.medical}\n`;
            analysisText += `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†ÙŠÙ: ${safeSearch.violence}\n`;
            analysisText += `â€¢ Ù…Ø­ØªÙˆÙ‰ Ø¥Ø¨Ø§Ø­ÙŠ: ${safeSearch.racy}\n\n`;
        }

        analysisText += "*Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Zaky AI Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±! ğŸ¤–*";

        await sock.sendMessage(chatId, { text: analysisText }, { quoted: quotedMessage, edit: statusMsg.key });

    } catch (error) {
        console.error('[Image Processor] Error analyzing image:', error);
        await sock.sendMessage(chatId, {
            text: "*âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.  ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Google Cloud Vision Ø£Ùˆ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ù†ÙØ³Ù‡Ø§. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© ØªØ§Ù†ÙŠØ©.*",
            edit: statusMsg.key
        }, { quoted: quotedMessage });

    } finally {
        fs.unlink(imagePath, (err) => {
            if (err) console.error(`[Image Processor] Error deleting file: ${err}`);
            else console.log(`[Image Processor] Temp file deleted: ${imagePath}`);
        });
    }
};

const handleImageMessage = async (sock, message) => {
    if (message.key.remoteJid === 'status@broadcast' || message.key.fromMe) {
        return;
    }

    const chatId = message.key.remoteJid;
    const quotedMessage = message;

    if (message.message?.imageMessage || message.message?.extendedTextMessage?.contextInfo?.quotedMessage?.imageMessage) {
        const imageMessage = message.message.imageMessage || message.message.extendedTextMessage.contextInfo.quotedMessage.imageMessage;

        const stream = await downloadContentFromMessage(imageMessage, 'image');
        let buffer = Buffer.from([]);  // <--  Ø§Ø³ØªØ®Ø¯Ù… 'let'
        for await (const chunk of stream) {
            buffer = Buffer.concat([buffer, chunk]);
        }

        const imageId = Date.now() + Math.floor(Math.random() * 1000);
        const tempImagePath = path.join(__dirname, '..', 'temp', `image_${imageId}.jpg`);

        const tempDir = path.join(__dirname, '..', 'temp');
        if (!fs.existsSync(tempDir)) {
            fs.mkdirSync(tempDir, { recursive: true });
        }

        fs.writeFileSync(tempImagePath, buffer);
        await processImage(sock, chatId, tempImagePath, quotedMessage);
    }
};

module.exports = {
    handleImageMessage,
};
